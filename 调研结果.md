# 推荐模型
我建议优先使用Spatio-Temporal Graph Convolutional Networks (STGCN) 或其物理增强版ST-GPINN (Spatio-Temporal Graph Physics-Informed Neural Network)，理由是它们平衡了时空捕捉和物理可解释性。备选模型包括DCRNN或CNN-LSTM+GNN混合。

| 模型名称                                                 | 核心架构                              | 为什么适合                                         | 优势                                                                 | 潜在局限                               | 示例应用                                  |
| ---------------------------------------------------- | --------------------------------- | --------------------------------------------- | ------------------------------------------------------------------ | ---------------------------------- | ------------------------------------- |
| STGCN (Spatio-Temporal Graph Convolutional Networks) | GCN（空间） + 1D-CNN或LSTM（时间）         | 直接处理图拓扑和时间序列；空间卷积捕捉设备连接，时间组件处理边界变化生成分钟级输出。    | 计算高效（稀疏图下O(N)复杂度）；易扩展到分钟级（通过时间插值或多层时间块）。准确率高，在能源网络预测中RMSE降低20-30%。 | 未显式融入物理定律，可能需额外损失函数约束。             | 风能/光伏功率预测（捕捉空间相关，如风场传播）；洪水模拟（类似流体动态）。 |
| ST-GPINN                                             | GNN（空间图消息传递） + PINN（时间演化 + PDE损失） | 建模管网为有向图，融入守恒方程（如质量/能量平衡PDE）作为损失；适合物理系统的高频预测。 | 物理一致性强（预测不会违反定律，如流量守恒）；对数据噪声鲁棒；在水管网水质预测中R²>0.95。                   | 需定义PDE（如管道的Navier-Stokes简化），计算稍复杂。 | 水分布系统预测（类似管网拓扑）；气体管道压力预测。             |
![[Pasted image 20250828150714.png]]
## 单变量时间预测
这里是单变量时间预测，然后做了标准的归一化，然后每次是
**分块 (Patching)**：输入的单变量时间序列首先被分解为连续的、不重叠的“块”（patches）15。每个块的长度由超参数 `input_patch_len` 决定2。例如，对于文中提到的200M模型，`input_patch_len` 被设置为 **32**6。这意味着每个原始数据块包含32个时间点。

• **输入令牌维度 (Input Token Dimension)**：每个原始数据块（patch）随后由一个**残差块 (Residual Block)** 处理，将其转换为一个**向量**，这个向量的维度被称为 `model_dim`12。这个 `model_dim` 是输入到Transformer层的令牌（token）的维度27。

    ◦ 对于主要的 **200M参数模型**，`model_dim` 设置为 **1280**6。

    ◦ 对于 **70M参数模型**，`model_dim` 设置为 **1024**8。

    ◦ 对于 **17M参数模型**，`model_dim` 设置为 **512**8. 将位置编码（positional encoding）添加到这些向量中，形成最终输入到Transformer层的令牌2。
## 其它时间预测模型
我现在是觉得这个MOIRAI吧这个多变量直接在时间维度上面拉长，然后用**Any-variate Attention**这件事太复杂了，就是这件事先拉长然后直接时间序列预测这件事就不太对。我还是比较相信预测下一个是对的、因为我这边这个多维度的呃变量太多了。
这里最后甚至是预测分布，这个也挺离谱的


---
title: Moirai 2.0 的“扁平化” (Flattening) 策略
date: 2024-05-21
tags:
  - Moirai
  - TimeSeries
  - Transformer
  - AI
---

> [!INFO]核心思想
> Moirai 2.0 通过一种**“扁平化” (Flattening)** 的策略来处理多变量时间序列问题，将多变量序列转换为一个更长的单变量式序列，并利用注意力机制学习变量间的依赖关系。

### 1. 数据转换与扁平化 (`_convert`)

在数据预处理阶段，模型并不为每个变量单独建立模型。相反，它将一个多变量序列（例如，维度为 `(context_length, target_dim)`）进行分块 (`patching`) 和重排 (`rearranging`)。

关键操作是 `rearrange` 函数，它将 `(时间步, 变量维度)` 的结构转换为一个更长的 `(令牌序列)` 结构。

> [!example] 举例说明
> 假设一个序列有 3个变量 (`target_dim=3`)，上下文长度在分块后得到 10个令牌。模型不会处理一个长度为10、维度为3的序列。相反，它会将其扁平化为一个长度为 **3 * 10 = 30** 的令牌序列。
> 
> 这个序列的排列通常是: `[var1_token1, ..., var1_token10, var2_token1, ..., var2_token10, var3_token1, ..., var3_token10]`。

### 2. 使用 `variate_id` 区分变量

> [!IMPORTANT] 变量身份识别
> 虽然序列被扁平化了，但模型需要知道每个令牌最初属于哪个变量。为此，在 `_convert` 步骤中，会为每个令牌生成一个 **`variate_id`**。

在上面的例子中，前10个令牌的 `variate_id` 会是0，接下来的10个是1，最后的10个是2。这个 `variate_id` 会作为元数据输入，传递给核心的 Transformer 模型。

### 3. 通过注意力偏置学习变量间关系

Transformer 模型的核心是自注意力机制。为了让模型理解并学习不同变量之间的相互影响，Moirai 2.0 使用了一个名为 `BinaryAttentionBias` 的特殊层。

> [!TIP] 学习跨变量依赖
> 这个层会接收所有令牌的 `variate_id`。当模型计算任意两个令牌之间的注意力分数时，`BinaryAttentionBias` 会根据这两个令牌的 `variate_id` 是否相同，为注意力分数添加一个**可学习的偏置 (bias)**。
> 
> 这意味着模型可以学习到类似于“变量A的某个时间点应该多大程度上关注变量B的另一个时间点”这样的跨变量依赖关系。

### 4. 输出重构

模型在内部以扁平化的方式生成预测后，`_format_preds` 函数会执行逆向操作。

它再次使用 `rearrange` 函数，将扁平化的预测令牌序列 (`dim * seq`) 重新构建为标准的多变量输出格式 `(prediction_length, target_dim)`。

### 总结

> [!SUCCESS] 结论
> Moirai 2.0 将多变量问题巧妙地转化为一个更长的序列建模问题，并通过为每个令牌分配 `variate_id` 并结合注意力偏置机制，让 Transformer 能够在一个统一的框架内有效学习和预测多变量时间序列中的复杂动态。

这里LOSTA这个数据集其实很少有超过10个变量的，大部分还是3-4个变量的情况，最多也有105个变量的，但是比起我们这个6000个变量是两个维度。

**最后预测的是分位数，这个太离谱了**

---
title: Moirai-2 模型的分位数预测与最终逻辑详解
date: 2025-08-28
tags:
  - Moirai
  - TimeSeries
  - DeepLearning
  - QuantilePrediction
  - 模型解析
---

### 1. 分位数预测 (Quantile Prediction) 是什么意思？

简单来说，传统的“点预测”只会给你一个最可能的结果，例如“明天的销售额将是1000元”。但这种预测没有告诉你任何关于**不确定性**的信息。实际销售额可能是900元或1100元吗？可能性有多大？

**分位数预测**就是为了解决这个问题。它不再预测一个单一的值，而是预测一系列的**分位数（Quantiles）**，从而给出一个未来结果的**可能范围**。

> [!INFO] 核心概念
> * **分位数 (Quantile)**：一个统计学概念，用来表示一个数据集中特定百分比的点。最常见的分位数是**中位数（Median）**，也就是第50个百分位数（$q_{0.5}$），它表示有50%的数据小于这个值。
> * **预测范围**：通过预测多个分位数，我们可以构建一个预测区间。例如：
>     * 预测第10个分位数（$q_{0.1}$）：代表一个悲观的预测，有90%的可能性，实际值会高于这个数。
>     * 预测第50个分位数（$q_{0.5}$）：代表最可能的预测（中位数）。
>     * 预测第90个分位数（$q_{0.9}$）：代表一个乐观的预测，只有10%的可能性，实际值会高于这个数。

那么，从 $q_{0.1}$ 到 $q_{0.9}$ 之间的范围就构成了一个**80%的预测区间**。这意味着我们有80%的信心认为，未来的实际值会落在这个区间内。

> [!IMPORTANT] 总结
> 分位数预测的核心优势在于它不仅提供了一个“最可能”的预测值，还通过预测值的可能范围来**量化了预测的不确定性**，这对于风险评估和决策制定至关重要。

---

### 2. Moirai-2 的最后逻辑详解

与预测完整概率分布的 Moirai 不同，Moirai-2 的架构被设计为直接、高效地输出预设好的分位数预测值。它的最后逻辑可以分解为以下几个关键步骤：

#### **第一步：在模型初始化时定义分位数**

在 `Moirai2Module` 的初始化函数 `__init__` 中，模型就已经定义好了它需要预测哪些分位数。
* `quantile_levels`: 这是一个包含所有目标分位数级别的元tuple，例如 `(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)`。
* `num_quantiles`: 这是分位数的总数，在这个例子中是 9。

#### **第二步：专门设计的输出层**

Moirai-2 的最后一层网络是一个名为 `out_proj` 的 `ResidualBlock`。这个输出层的设计是整个逻辑的核心，它的输出维度被精确地设置为：
`num_predict_token * self.num_quantiles * patch_size`。

这意味着，对于模型一次预测的每个时间步（由`patch_size`定义），输出层都会为**每一个预定义的分位数**生成一个具体的值。它直接学习如何映射到这些分位数，而不是学习一个概率分布的参数。

#### **第三步：前向传播直接生成预测值**

在 `Moirai2Module` 的 `forward` 方法中，数据经过 Transformer 编码器处理后，得到的特征表示 `reprs` 被送入 `out_proj` 层，直接计算出预测值 `preds`。
* 在推理模式下 (`training_mode=False`)，模型会返回 `preds * scale + loc`。这表明网络输出的是经过归一化的分位数预测值，需要通过反向缩放（乘以方差 `scale` 再加上均值 `loc`）来得到最终的真实数值。
* **关键区别**：这里返回的是一个包含具体数值的张量（Tensor），而不是像 Moirai 那样返回一个可以采样的分布对象。

#### **第四步：在预测模块中进行自回归（Auto-regression）**

`Moirai2Forecast` 模块负责管理整个预测流程。当需要预测的未来时间长度（`prediction_length`）超过模型单次能输出的长度时，它会采用一种**自回归**的方式：

1.  模型首先预测未来最近的几个时间步（例如第1个 patch）的所有分位数。
2.  然后，它会将**上一步预测出的分位数结果**（通常是中位数，即 $q_{0.5}$ 的值）作为新的输入，去预测再往后的几个时间步（例如第2个 patch）。
3.  这个过程会循环进行，直到生成所有需要预测的时间长度。

#### **第五步：格式化输出**

最后，`Moirai2Forecast` 模块会使用 `_format_preds` 等函数以及 `gluonts` 库中的 `QuantileForecastGenerator` 来整理和重塑输出张量。最终的输出格式通常是 `(批次大小, 分位数数量, 预测时间长度)`，非常清晰地展示了在每个未来时间点上，所有不同分位数的预测值。

> [!summary] Moirai-2 最终逻辑流程总结
> **输入数据** -> **Transformer编码器** -> **特征表示 (`reprs`)** -> **`out_proj` 输出层 (为每个分位数直接生成值)** -> **原始分位数预测张量 (`preds`)** -> **(如有需要，进行自回归循环预测)** -> **整理格式** -> **最终的分位数预测结果**



## 超大变量的时间序列问题
一个最初看似有悖常理的发现是，在处理高维数据时，一些设计精密的通道依赖模型（旨在捕捉变量间相关性）的性能反而不如更简单的通道独立（Channel-independent）模型 。例如，在Crime-Chicago、Wiki-People和Traffic等高维数据集上的实验表明，先进的通道依赖模型Crossformer的准确性平均比通道独立的PatchTST低19% 。  

这一现象的根本原因在于“噪声放大效应”。在一个包含数千个变量的系统中，与预测目标强相关的变量可能只占少数。当模型试图学习一个全局的、密集的变量关系矩阵时，大量不相关或弱相关变量引入的噪声会淹没掉关键的信号。这极大地增加了模型捕捉核心依赖关系的难度，导致性能下降 。早期通道依赖模型隐含的“更多信息（来自其他通道）总是更好”的假设在高维场景下被证伪。这一关键的经验性失败，促使研究界进行了一次重要的范式转换：从试图“建模所有交互”转向更为精细的“建模有意义的交互”。这种转变直接催生了旨在主动过滤、稀疏化或结构化变量间信息的新一代架构。
> [!WARNING]
> 主要是我觉得管道这个项目就不太是这种很需要时间序列预测的，因为感觉主要是被管道的其它影响。
> 就问清楚一个问题，就是天然气管道运输的影响主要受到历史影响多？还是受到周围的管道其它影响多？

# TOTO 论文
---
title: Toto 模型架构解析：输入、维度变化与输出
date: 2025-08-28
tags:
  - AI
  - 模型解析
  - 时间序列
  - Transformer
  - Toto
---

### 核心摘要

> [!INFO] 核心摘要
> **Toto (Timeseries-Optimized Transformer for Observability)** 是一个基于Transformer的、专为多元时间序列预测设计的模型。简单来说，它接收一批时间序列数据，通过一个专门的Transformer架构进行处理，并为每个时间点输出一个概率分布（例如学生t-分布），而不是一个单一的预测值。这使得模型能够在其预测中表达不确定性。

---

### 模型输入

> [!IMPORTANT] 模型输入
> 模型的主要入口点是 `TotoBackbone` 类 (`backbone.py`) 中的 `forward` 方法。它接收以下主要输入：

| 参数 | 维度 | 描述 |
| :--- | :--- | :--- |
| `inputs` | `(batch, variate, time_steps)` | 这是包含时间序列数据的核心输入张量。`batch` 是批次中的时间序列样本数量，`variate` 是每个时间序列中不同指标或变量的数量，`time_steps` 是序列的长度。 |
| `input_padding_mask` | `(batch, variate, time_steps)` | 一个布尔张量，用于指示 `inputs` 中的哪些值是填充值，在计算统计数据（如均值和标准差）时应被忽略。 |
| `id_mask` | `(batch, variate, time_steps)` | 一个整数张量，用于识别同一批次中不同的时间序列。这对于“空间维度注意力”（space-wise attention）至关重要，确保模型只关注属于同一逻辑组的变量。 |

---

### 维度变化流程（分步解析）

> [!NOTE] 维度简称
> 我们将使用以下维度简称：
> * **B**: `batch` (批次大小)
> * **V**: `variate` (变量数量)
> * **T**: `time_steps` (时间步长)
> * **P**: `patch_size` (切片大小，一个超参数)
> * **S**: `seq_len` (切片数量, 约等于 `T / P`)
> * **D**: `embed_dim` (模型的内部隐藏维度)
注意这里输入缩放肯定是在模型里面做

#### 1. 输入缩放 (`scaler.py`) 
第一步是标准化输入数据。模型使用一个缩放器（例如 `CausalPatchStdMeanScaler`）将数据的均值调整为0，标准差调整为1。这个过程是“因果的”（causally），意味着在给定时间步 `t` 的统计数据仅使用从时间 `0` 到 `t` 的数据来计算。

* **输入形状**: `(B, V, T)`
* **操作**: 因果标准化。此步骤还会计算并保存原始数据的均值 (`loc`) 和标准差 (`scale`)。这些值后续用于将模型输出还原到原始尺度。
* **输出形状**: 数据张量的形状保持不变。
    * `scaled_inputs`: `(B, V, T)`
    * `loc`: `(B, V, T)`
    * `scale`: `(B, V, T)`

#### 2. 切片嵌入 (`embedding.py`)
连续的时间序列数据被分解成多个“切片”（patches）。每个切片是时间序列的一个小段（例如，32个时间步）。然后，这些切片被投影到模型的高维潜在空间（`embed_dim`）中。

* **输入形状**: `(B, V, T)`
* **操作**:
    1.  时间维度 `T` 被“展开”成 `S` 个大小为 `P` 的切片。形状变为 `(B, V, S, P)`。
    2.  对每个切片应用一个线性投影，将其维度从 `P` 映射到 `D`。
* **输出形状**: `(B, V, S, D)`

#### 3. Transformer 层 (`transformer.py` & `attention.py`)
这是模型的核心部分。经过切片处理的数据流经一系列Transformer层。Toto的一个关键特性是它在两种注意力机制之间交替进行：

* **时间维度注意力 (Time-Wise Attention)**: 在时间维度 (`S`) 上进行注意力计算。模型会重排数据，以便能够独立地为每个变量寻找时间模式。
    * **数据重排**: `(B, V, S, D)` -> `(B * V, S, D)`
* **空间维度注意力 (Space-Wise Attention)**: 在变量维度 (`V`) 上进行注意力计算。模型会重排数据，以便能够在同一时间点上寻找不同变量之间的关系。
    * **数据重排**: `(B, V, S, D)` -> `(B * S, V, D)`

Transformer应用这些注意力机制，然后是前馈网络，但它会保持张量的整体形状不变。

* **输入形状**: `(B, V, S, D)`
* **操作**: 一系列自注意力（self-attention）和前馈网络层，它们在不改变张量形状的情况下处理信息。
* **输出形状**: `(B, V, S, D)`

#### 4. 反嵌入 / 投影头 (`backbone.py`)
在Transformer处理完切片数据后，模型需要将其转换回与原始时间序列长度相对应的格式。这本质上是切片嵌入过程的逆操作。

* **输入形状**: `(B, V, S, D)`
* **操作**:
    1.  一个线性层将嵌入维度 `D` 投影到一个更大的维度 `(P * D)`。形状变为 `(B, V, S, P * D)`。
    2.  张量被重排，将切片“压平”并还原成连续的时间维度。`S` 和 `P` 维度被合并。
* **输出形状**: `(B, V, T, D)`

---

### 模型输出 (`backbone.py` & `distribution.py`)

> [!WARNING] 模型输出提醒
> 最终的输出不是每个时间步的单一数值，而是一个统计分布。

#### 1. 分布投影 (`distribution.py`)
“反嵌入”步骤的最终张量被传递给一个输出分布模块（例如 `StudentTOutput`）。该模块使用线性层将嵌入维度 `D` 投影到定义每个时间点分布所需的参数上。

* **输入形状**: `(B, V, T, D)`
* **操作**: 对于 `StudentTOutput`，三个独立的线性层将 `D` 维度投影到1，为每个点创建三个参数：
    * 自由度 (`df`)
    * 基础位置 (`base_loc`)
    * 基础尺度 (`base_scale`)
* **参数形状**: 每个参数张量的形状都是 `(B, V, T)`。

#### 2. 最终输出对象 (`backbone.py`)

`forward` 方法返回一个 `TotoOutput` 对象，这是一个包含三项内容的 `NamedTuple`（命名元组）：

| 字段 | 类型 | 描述 |
| :--- | :--- | :--- |
| `distribution` | `torch.distributions.Distribution` | 这是一个PyTorch的分布对象（例如 `AffineTransformed(StudentT(...))`）。它封装了整个批次所有预测的分布参数。您可以使用此对象来计算实际值的对数概率（`.log_prob()`）或从预测的分布中抽取样本（`.sample()`）。该分布的“事件形状”（event shape）与输入维度相对应：**`(B, V, T)`**。 |
| `loc` | `torch.Tensor` | 这是从缩放步骤传递过来的、原始未缩放数据的均值张量。其维度为 **`(B, V, T)`**。 |
| `scale` | `torch.Tensor` | 这同样是来自缩放步骤的、原始未缩放数据的标准差张量。其维度为 **`(B, V, T)`**。 |

总而言之，模型的最终输出是为输入时间序列中的每一个点学习到的一个概率分布，您可以从中推导出预测值、置信区间以及其他统计洞见。
# 最后结论
仔细看了下还是不如这个
突然感觉到这不是一个好问题，建议不要花太多时间，水一篇论文就好了。主要是用zhr的影响力。